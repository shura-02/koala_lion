{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kP9sW-7S7gFu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0,\n",
        "                                                                shear_range = 0.2,\n",
        "                                                                horizontal_flip = True)\n",
        "\n",
        "training_data = training_datagen.flow_from_directory(\"/content/drive/MyDrive/Data Sets/koala_lion_Classification/train\",\n",
        "                                                     target_size = (180,180),\n",
        "                                                     batch_size = 32,\n",
        "                                                     class_mode = 'binary')\n",
        "\n",
        "testing_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "testing_data = testing_datagen.flow_from_directory(\"/content/drive/MyDrive/Data Sets/koala_lion_Classification/test\",\n",
        "                                                    target_size = (180,180),\n",
        "                                                     batch_size = 32,\n",
        "                                                     class_mode = 'binary')"
      ],
      "metadata": {
        "id": "oPwpTCP38aF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770b196a-b8c1-4dfd-da27-1775972b505b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 144 images belonging to 2 classes.\n",
            "Found 37 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = keras.applications.vgg16.VGG16(include_top = False,\n",
        "weights = 'imagenet',\n",
        "input_shape = (180,180,3),\n",
        "pooling = 'avg',\n",
        "classes = 2)\n",
        "\n",
        "for layers in pre_trained_model.layers:\n",
        "  layers.trainable = False  \n"
      ],
      "metadata": {
        "id": "07DgToBx_PKb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(pre_trained_model)\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(128, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "AOGbrwgy_O0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2b11db-acb8-48d7-d281-6ba2ad3e9290"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 512)               14714688  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,780,481\n",
            "Trainable params: 65,793\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'Adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(training_data,\n",
        "          epochs = 5,\n",
        "          validation_data = testing_data)"
      ],
      "metadata": {
        "id": "yfehf4OK_NT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38711db7-e2fa-47c3-a106-170065c2ac6b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 60s 12s/step - loss: 0.6325 - accuracy: 0.6250 - val_loss: 0.6402 - val_accuracy: 0.5135\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 58s 12s/step - loss: 0.5730 - accuracy: 0.6042 - val_loss: 0.5248 - val_accuracy: 0.8378\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 57s 12s/step - loss: 0.4722 - accuracy: 0.8403 - val_loss: 0.4892 - val_accuracy: 0.8378\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 59s 12s/step - loss: 0.4190 - accuracy: 0.8889 - val_loss: 0.4402 - val_accuracy: 0.8378\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 57s 12s/step - loss: 0.3587 - accuracy: 0.9583 - val_loss: 0.4178 - val_accuracy: 0.8108\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa99687a220>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_array = keras.preprocessing.image.load_img(\"/content/drive/MyDrive/Data Sets/koalabhai.jfif\",\n",
        "                                                 target_size = (180,180))\n",
        "image_array = keras.preprocessing.image.img_to_array(image_array)\n",
        "print(image_array)\n",
        "image_array = np.expand_dims(image_array, axis = 0)\n",
        "print(image_array.shape)\n",
        "if model.predict(image_array) > 0.5:\n",
        "  print(\"Lion mama\")\n",
        "else:\n",
        "  print(\"Koala anna\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPYRYcs-GwNs",
        "outputId": "bab46589-ae8f-442c-afad-d5537559e2e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[119. 125. 121.]\n",
            "  [135. 144. 141.]\n",
            "  [145. 155. 154.]\n",
            "  ...\n",
            "  [195. 210. 181.]\n",
            "  [182. 198. 159.]\n",
            "  [168. 188. 135.]]\n",
            "\n",
            " [[124. 130. 126.]\n",
            "  [141. 147. 143.]\n",
            "  [149. 158. 157.]\n",
            "  ...\n",
            "  [181. 196. 165.]\n",
            "  [173. 190. 148.]\n",
            "  [173. 193. 140.]]\n",
            "\n",
            " [[133. 140. 133.]\n",
            "  [144. 150. 146.]\n",
            "  [148. 157. 154.]\n",
            "  ...\n",
            "  [171. 185. 150.]\n",
            "  [160. 177. 133.]\n",
            "  [168. 186. 136.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 74. 102.  54.]\n",
            "  [ 73. 102.  56.]\n",
            "  [ 76. 107.  65.]\n",
            "  ...\n",
            "  [118. 132. 115.]\n",
            "  [109. 124. 105.]\n",
            "  [107. 125. 103.]]\n",
            "\n",
            " [[ 73. 100.  59.]\n",
            "  [ 78. 105.  64.]\n",
            "  [ 84. 114.  76.]\n",
            "  ...\n",
            "  [116. 131. 112.]\n",
            "  [106. 121. 100.]\n",
            "  [102. 120.  96.]]\n",
            "\n",
            " [[ 82. 106.  72.]\n",
            "  [ 79. 105.  70.]\n",
            "  [ 82. 109.  76.]\n",
            "  ...\n",
            "  [108. 123. 102.]\n",
            "  [ 99. 114.  91.]\n",
            "  [ 96. 114.  88.]]]\n",
            "(1, 180, 180, 3)\n",
            "1/1 [==============================] - 0s 325ms/step\n",
            "Koala anna\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "6Hb3b_Jl9J2r"
      }
    }
  ]
}